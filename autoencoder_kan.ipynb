{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGqlhlMCLVLq"
      },
      "source": [
        "# autoencoder KAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORCTqi0gQPWe"
      },
      "source": [
        "## MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcXld9kBMH5I",
        "outputId": "598c1a5d-084b-4b47-d91a-02455fe86454"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 938/938 [00:34<00:00, 26.92it/s, loss=0.0569]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Train Loss: 0.1139\n",
            "Epoch 1, Val Loss: 0.0548\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 938/938 [00:34<00:00, 26.93it/s, loss=0.0422]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Train Loss: 0.0473\n",
            "Epoch 2, Val Loss: 0.0406\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 938/938 [00:35<00:00, 26.74it/s, loss=0.035]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Train Loss: 0.0377\n",
            "Epoch 3, Val Loss: 0.0348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 938/938 [00:35<00:00, 26.58it/s, loss=0.0281]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Train Loss: 0.0330\n",
            "Epoch 4, Val Loss: 0.0312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 938/938 [00:35<00:00, 26.68it/s, loss=0.0326]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Train Loss: 0.0302\n",
            "Epoch 5, Val Loss: 0.0291\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 938/938 [00:35<00:00, 26.70it/s, loss=0.025]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Train Loss: 0.0283\n",
            "Epoch 6, Val Loss: 0.0275\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 938/938 [00:34<00:00, 26.95it/s, loss=0.0243]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Train Loss: 0.0269\n",
            "Epoch 7, Val Loss: 0.0264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 938/938 [00:34<00:00, 26.82it/s, loss=0.0245]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Train Loss: 0.0259\n",
            "Epoch 8, Val Loss: 0.0256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████| 938/938 [00:35<00:00, 26.20it/s, loss=0.0263]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Train Loss: 0.0252\n",
            "Epoch 9, Val Loss: 0.0250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|██████████| 938/938 [00:35<00:00, 26.21it/s, loss=0.0246]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Train Loss: 0.0246\n",
            "Epoch 10, Val Loss: 0.0245\n",
            "Training completed and model saved.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import KAN\n",
        "\n",
        "# Load MNIST\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
        ")\n",
        "trainset = torchvision.datasets.MNIST(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "valset = torchvision.datasets.MNIST(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "valloader = DataLoader(valset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define Sparse Autoencoder model using KAN\n",
        "class SparseKANAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim, grid_size=5, spline_order=3):\n",
        "        super(SparseKANAutoencoder, self).__init__()\n",
        "        self.encoder = KAN([input_dim, hidden_dim, latent_dim], grid_size=grid_size, spline_order=spline_order)\n",
        "        self.decoder = KAN([latent_dim, hidden_dim, input_dim], grid_size=grid_size, spline_order=spline_order)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "# Initialize model, criterion, optimizer, and scheduler\n",
        "input_dim = 28 * 28\n",
        "hidden_dim = 128\n",
        "latent_dim = 64\n",
        "model = SparseKANAutoencoder(input_dim, hidden_dim, latent_dim)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    with tqdm(trainloader, desc=f\"Epoch {epoch+1}/{num_epochs}\") as pbar:\n",
        "        for images, _ in pbar:\n",
        "            images = images.view(-1, 28 * 28).to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, images)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            pbar.set_postfix(loss=loss.item())\n",
        "\n",
        "    train_loss /= len(trainloader.dataset)\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for images, _ in valloader:\n",
        "            images = images.view(-1, 28 * 28).to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, images)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "    val_loss /= len(valloader.dataset)\n",
        "    print(f\"Epoch {epoch+1}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # Update learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "# Save the model for further analysis and explainability\n",
        "torch.save(model.state_dict(), \"sparse_kan_autoencoder.pth\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
